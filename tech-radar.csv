name,ring,quadrant,isNew,description
"Data Quality: Quality monitoring in New Relic","ADOPT","Languages & Frameworks","false","<p>We already use <a href=""https://newrelic.com/"">New Relic</a> to dashboard and alert system health, and it’s the natural choice for doing the same with data health. Some of our pipelines already send data metrics to New Relic in addition to storing them on S3, and we should make this the standard for pipelines going forward.</p>"
"localstack for integration testing with AWS","ADOPT","Languages & Frameworks","false","<p>Our historical approaches for components which interact with AWS has either been to mock the interactions or run against a real environment. The <a href=""https://github.com/localstack/localstack"">localstack</a> library enable us to write tests which are stronger than mock tests, and are not coupled to real environments.</p>"
"testcontainers with docker-compose for containerised tests","ADOPT","Languages & Frameworks","false","<p>We have used <a href=""https://www.testcontainers.org/"">Testcontainers</a> with docker-compose to simplify testing against containerised services and it has increased the test strength and reduced test complexity. Building on top of docker-compose also ensures that our test environment aligns with our command line environment.</p>"
"Feature Store","ADOPT","Techniques","false","<p>We built a <a href=""https://www.featurestore.org/"">Feature Store</a> for one of our recent products to host features for models to consume. This will reduce test/train skew and has accelerated Data Science delivery of new models into production. We should adopt this practice for future models we deliver, and start to build a library of useful features for Data Scientists to use.</p>"
"Orchestration: Airflow","ADOPT","Tools","false","<p>We’re migrating our orchestration framework from AWS Data Pipelines to <a href=""https://airflow.apache.org/"">Apache Airflow</a>. This has moved from TRIAL to ADOPT because initial Airflow spikes were promising, and now that AWS Data Pipelines are end-of-life we have no option but to make the change.</p>"
"Data Quality: Great Expectations for data checks","TRIAL","Languages & Frameworks","false","<p>We need stronger data checks to ensure that we are alerted when our data deviates from what we expect. <a href=""https://greatexpectations.io/"">Great Expectations</a> is a Python library aimed at these types of data checks.</p> <p>This has evolved since we last looked at it and is increasingly gaining momentum. We should assess whether it is useful by running a cheap proof-of-concept trial.</p>"
"Data Quality: OpenLineage for data lineage tracking","TRIAL","Languages & Frameworks","false","<p>OpenLineage is an open standard for tracking data lineage in which tools send information to a central server when they use or generate data, and this usage information can track the lineage of a data set back and forward in time.</p> <p>As we focus more on data quality lineage tracking will become increasingly important, and OpenLineage could fill that gap. There are several interesting integrations and synergies with our tools (<a href=""https://openlineage.io/docs/integrations/spark/"">Spark</a>, <a href=""https://openlineage.io/docs/integrations/airflow/"">Airflow</a>, <a href=""https://openlineage.io/docs/integrations/great-expectations"">Great Expectations</a>, and <a href=""https://marquezproject.github.io/marquez/"">Marquez</a> for visualisation).</p> <p>We should consider a small proof-of-concept to trial the tools and assess usefulness.</p>"
"Tracking tech health rather than tech debt","TRIAL","Techniques","false","<p>Technical debt is a recurring topic for product owners and engineering but the term isn’t particularly helpful. There’s no differentiation between ""good"" and ""bad"" technical debt, and it doesn’t help focus attention on the areas where paying off debt is useful.</p> <p>Some teams are experimenting with flipping the conversation. Instead of talking about areas with debt (which legacy systems may have a lot of), they talk about the areas that are good. By ensuring that areas that need rapid iteration are healthy, we can focus attention where it will have the best payoff. <a href=""https://www.rea-group.com/about-us/news-and-insights/blog/what-good-software-looks-like-at-rea/"">REA</a> have a good example of what ""good"" looks like for their teams.</p> <p>I’d like to experiment with this for teams here to see if it helps focus conversation.</p>"
"Data Quality: pandera for data checks","ASSESS","Languages & Frameworks","false","<p><a href=""https://pandera.readthedocs.io/en/stable/"">pandera</a> is an alternative to Great Expectations. It is Spark compatible, and because it is Python-based and lightweight it may be more suitable for data science to write quick tests.</p>"
"Data Quality: popmon for data checks","ASSESS","Languages & Frameworks","false","<p><a href=""https://github.com/ing-bank/popmon"">popmon︎</a> is a popular Python library for monitoring population shifts in data sets. This could be useful for monitoring our model inputs to verify that our assumptions continue to hold in production.</p>"
"GraphQL: Netflix DGS for GraphQL APIs","ASSESS","Languages & Frameworks","false","<p><a href=""https://netflix.github.io/dgs/"">DGS</a> is Netflix’s library for GraphQL services. It’s mature, Spring-compatible, and works well with Java and Kotlin services.</p>"
"LLMs: DSPy for prompt programming","ASSESS","Languages & Frameworks","false","<p><a href=""https://github.com/stanfordnlp/dspy"">DSPy</a> is a framework for programming and evolving prompts, rather than the human-in-the-loop iterative development that we currently use.</p>"
"LLMs: GPTCache for semantic LLM caching","ASSESS","Languages & Frameworks","false","<p>Traditional caching strategies aren’t useful with free form GenAI queries, but there may be some mileage in using <a href=""https://github.com/zilliztech/GPTCache"">GPTCache</a> to semantically cache responses. It might be worth looking at for some of our use-cases.</p>"
"LLMs: LLMLingua for prompt compression and quality improvement","ASSESS","Languages & Frameworks","false","<p><a href=""https://github.com/microsoft/LLMLingua"">LLMLingua</a> is a library that Microsoft has found both reduces prompt token count by 20 percent and also in some use-cases increases performance by removing low value tokens.</p>"
"LLMs: Semantic Kernel for building LLM applications with agents","ASSESS","Languages & Frameworks","false","<p><a href=""https://pypi.org/project/semantic-kernel/"">semantic-kernel</a> is part of Microsoft’s GitHub Copilot, aimed at building applications on top of LLMs and containing an agent planning framework.</p>"
"LLMs: promptfoo for prompt development","ASSESS","Languages & Frameworks","false","<p><a href=""https://github.com/promptfoo/promptfoo"">promptfoo</a> is a TDD framework for prompt development.</p>"
"Backstage as a service portal","ASSESS","Platforms","false","<p>We have many APIs and services, and no centralised hub with documentation to direct developers to our services. <a href=""https://backstage.io/"">Backstage</a> is Spotify’s solution for providing this service, and we now have an instance of this running in the group. We should assess whether it’s useful for our needs, and if so then start hosting our content there.</p>"
"Firecracker for containerisation","ASSESS","Platforms","false","<p><a href=""https://firecracker-microvm.github.io/"">Firecracker</a> is a lightweight micro VM platform which is gaining traction for being significantly easier to manage than Kubernetes. For scaling problems that aren’t Google or Netflix scale, it may require lower initial and ongoing investment from engineering teams. We should assess whether it makes our life easier.</p>"
"Modelling: TypeDB for domain modelling","ASSESS","Platforms","false","<p><a href=""https://github.com/vaticle/typedb"">TypeDB</a> is a strongly-typed database which enables you to model complex domains and knowledge graphs using inheritance, and to query them using a built-in query language.</p> <p>This could be a useful tool for modelling complex domains cheaply before committing to a design.</p>"
"Agile: OpenRewrite for mass refactoring","ASSESS","Tools","false","<p><a href=""https://github.com/openrewrite/rewrite"">openrewrite/rewrite</a> is a way of handling mass rewrites of code, such as library upgrades or patches. This could be something we could look at to reduce the cost of security patching or handling EOL packages.</p>"
"Agile: mob for pair-programming","ASSESS","Tools","false","<p><a href=""https://github.com/remotemobprogramming/mob"">mob</a> looks like a fun tool for streamlining pair-programming sessions. We should play with it and see whether it helps streamline handover.</p>"
"Copilots: Cline as a coding buddy","ASSESS","Tools","false","<p><a href=""https://github.com/cline/cline"">cline</a> is a VS Code plugin coding buddy which covers both the IDE and command line.</p>"
"Copilots: Cursor as a coding buddy","ASSESS","Tools","false","<p><a href=""https://www.cursor.com/en"">Cursor</a> is an AI-oriented IDE which has impressive performance relative to other copilots.</p>"
"Copilots: GitHub copilot as a coding buddy","ASSESS","Tools","false","<p><a href=""https://github.com/features/copilot"">GitHub Copilot</a> has the potential to accelerate coding and initial feedback has been favourable. We should experiment with the tool and assess where it is useful, and where it struggles.</p>"
"Copilots: Roo Code as a coding buddy","ASSESS","Tools","false","<p><a href=""https://roocode.com/"">Roo Code</a> is a VS Code plugin which can use a variety of back-end LLMs.</p>"
"Copilots: Tabnine as a coding buddy","ASSESS","Tools","false","<p><a href=""https://www.tabnine.com/"">Tabnine</a> is a self-hosted open source coding buddy. It addresses some of the concerns we have around GitHub Copilot’s hosting and proprietary knowledge.</p>"
"Copilots: Windsurf as a coding buddy","ASSESS","Tools","false","<p><a href=""https://windsurf.com/editor"">Windsurf</a> (previously called Codeium) is a self-hosted open source coding buddy. It’s relatively new, but addresses some of the concerns we have around GitHub Copilot’s hosting and proprietary knowledge.</p>"
"ETL: AWS Glue","ASSESS","Tools","false","<p>We have been looking at ways to reduce the time it takes to write our ETL jobs. <a href=""https://aws.amazon.com/glue/"">AWS Glue</a> is a managed ETL service which provides drag-and-drop ETL logic, integration with S3 batch and Kafka streaming sources, and a data catalogue which abstracts out the location and format of the data to make it simple to combine data from different sources. There are many in-built transformations for ETL, and custom transformations can be loaded.</p> <p>The features it provides look like they might satisfy some of the needs we have (reducing the time to write ETL jobs, combining data from multiple sources, discovering data sets). We should assess whether this is useful either as a part of our experimentation platform or our production systems.</p>"
"ETL: Ray","ASSESS","Tools","false","<p>We have been looking at ways to reduce the time it takes to write our ETL jobs. <a href=""https://docs.ray.io/en/latest/index.html"">Ray</a> is a framwork for scaling Python-based ETL cheaply.</p> <p>The features it provides look like they might satisfy some of the needs we have (reducing the time to write ETL jobs, combining data from multiple sources, discovering data sets). We should assess whether this is useful either as a part of our experimentation platform or our production systems.</p>"
"ETL: Spark over Kafka","ASSESS","Tools","false","<p>We currently use Spark for our batch big data jobs, but are looking at how to move to an incremental and streaming model -- this will simplify integration with the data platform, reduce latency, and reduce costs. Kafka streaming may be the choice for Kafka-to-Kafka jobs, but we should also investigate whether Spark streaming over Kafka will allow more reuse of components and perhaps support both batch and streaming jobs.</p>"
"ETL: Spark over Kubernetes","ASSESS","Tools","false","<p>We currently run our Spark jobs using AWS EMR. This generally works fine, but there are some shortcomings: clusters are not very resilient, logs are difficult to access and verbose, clusters are often oversized, and we have limited control over the stack used.</p> <p>EMR on EKS is looking increasingly attractive -- it is <a href=""https://aws.amazon.com/blogs/big-data/amazon-emr-on-eks-widens-the-performance-gap-run-apache-spark-workloads-5-37-times-faster-and-at-4-3-times-lower-cost/"">faster and cheaper than EMR</a>, and <a href=""https://aws.amazon.com/about-aws/whats-new/2023/04/emr-eks-apache-spark-java-11/"">now supports Java 11</a> more easily. We should assess the costs of trialling this.</p>"
"ML: Polynote","ASSESS","Tools","false","<p>Investigate <a href=""https://polynote.org/"">Polynote</a> for cheap experiments and automation.</p>"
"ML: flyte","ASSESS","Tools","false","<p>Investigate <a href=""https://github.com/flyteorg/flyte"">flyteorg/flyte</a> for MLOps</p>"
"Orchestration: Ray","ASSESS","Tools","false","<p><a href=""https://github.com/ray-project/ray/"">Ray</a> is a framework for scaling Python workflows which is proving popular in the ML community. We should assess whether this offers any benefits over our traditional ways of orchestrating workflows (Airflow and EMR, generally).</p>"
"Granular libraries","HOLD","Techniques","false","<p>We are struggling to refactor and renovate our code because the library abstractions we have built are too granular. We should consider reducing the number of abstraction layers in our systems, and optimise for agility rather than for minimising reducing duplication.</p>"
"APIs: Akka","HOLD","Tools","false","<p><a href=""https://akka.io/"">Akka</a> and frameworks built on top of it (like AkkaHTTP for APIs, and Akka Flow for long-running jobs) has moved to HOLD and we aren’t considering it for new projects.</p> <p>In the majority of cases when we used it, the technology added incidental complexity and difficulty rather than simplifying the work. We found it difficult to debug problems in the asynchronous flows, profiling was hard, and the application was difficult to tune. It may be that there are problems where Akka is a good fit, but for APIs and batch processing jobs there are simpler alternatives. Additionally, the <a href=""https://www.lightbend.com/blog/why-we-are-changing-the-license-for-akka"">license</a> has recently become more restrictive and this affects projects built on top of Akka.</p>"
"ML: Kubeflow","HOLD","Tools","false","<p>We already use Kubernetes to scale our services, and running ML models on Kubernetes using <a href=""https://www.kubeflow.org/docs/about/kubeflow/"">Kubeflow</a> would fit well with our existing architecture.</p> <p>The roadmap for Kubeflow looks ambitious, but it is evolving unevenly. Much of the documentation seems incomplete or out of date and some parts of the ecosystem seem to be discontinued (e.g., Fairing is a version behind and hasn’t been updated since July 2020) or just very light on details. There are also several stories from the community about difficulties with the platform (e.g., <a href=""https://www.datarevenue.com/en-blog/kubeflow-not-ready-for-production"">Kubeflow: Not ready for production?</a>).</p>"
