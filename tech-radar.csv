Data quality monitoring in New Relic	ADOPT	Quality	false	<p>We already use New Relic to dashboard and alert system health, and it’s the natural choice for doing the same with data health. Some of our pipelines already send data metrics to New Relic in addition to storing them on S3, and we should make this the standard for pipelines going forward.</p>
localstack for integration testing with AWS	ADOPT	Quality	false	<p>Our historical approaches for components which interact with AWS has either been to mock the interactions or run against a real environment. The localstack library enable us to write tests which are stronger than mock tests, and are not coupled to real environments.</p>
testcontainers with docker-compose for containerised tests	ADOPT	Quality	false	<p>We have used testcontainers with docker-compose to simplify testing against containerised services and it has increased the test strength and reduced test complexity. Building on top of docker-compose also ensures that our test environment aligns with our command line environment.</p>
Incremental delivery	ADOPT	Techniques	false	
Pipelines: Delta Lake	TRIAL	Engineering	false	
SonarQube as a useful quality metric	TRIAL	Quality	false	<p>SonarQube is used as standard in our builds, but the results are mostly ignored because the configured profiles give very poor signal-to-noise. If we are being pushed to use this more in the future and results will be monitored by management then we should experiment with tweaking the configuration to see if we can make it useful for us.</p>
ML: Tensorflow over Kubernetes	ASSESS	Engineering	false	
Orchestration: Airflow	ASSESS	Engineering	false	<p>We’re currently looking to replace our orchestration framework. <a href="https://airflow.apache.org/">Apache Airflow</a> is a mature and stable offering in this space that we should investigate.</p>
Pipelines: Spark over Kafka	ASSESS	Engineering	false	<p>We currently use Spark for our batch big data jobs, but are looking at how to move to an incremental and streaming model -- this will simplify integration with the data platform, reduce latency, and reduce costs. Kafka streaming may be the choice for Kafka-to-Kafka jobs, but we should also investigate whether Spark streaming over Kafka will allow more reuse of components and perhaps support both batch and streaming jobs.</p>
Pipelines: Spark over Kubernetes	ASSESS	Engineering	false	<p>We currently run our Spark jobs using AWS EMR. This generally works fine, but there are some shortcomings: clusters are not very resilient, logs are difficult to access and verbose, clusters are often oversized, and we have limited control over the stack used. Spark has added the ability to run over Kubernetes and AWS offers <a href="https://aws.amazon.com/blogs/opensource/deploying-spark-jobs-on-amazon-eks/">some support</a> in this area and this may remove some of the shortcomings we see with EMR.</p>
AWS Cloud Development Kit as a Terraform replacement	ASSESS	Infrastructure	false	
Backstage as a service portal	ASSESS	Infrastructure	false	
CI/CD: Tekton over Kubernetes	ASSESS	Infrastructure	false	
Great Expectations for data checks	ASSESS	Quality	false	
Feature Store	ASSESS	Techniques	false	
APIs: Akka	HOLD	Engineering	false	<p>We’ve used <a href="https://akka.io/">Akka</a> in a few different forms on several projects, including AkkaHTTP for APIs and Akka Flow for long running batch processing jobs. In the majority of those cases, the technology added incidental complexity and difficulty rather than simplifying the work. We found it difficult to debug problems in the asynchronous flows, profiling was hard, and the application was difficult to tune. It may be that there are problems where Akka is a good fit, but for APIs and batch processing jobs there are simpler alternatives which we’d pick in preference next time.</p>
Orchestration: AWS Data Pipelines	HOLD	Engineering	false	<p>We use <a href="https://aws.amazon.com/datapipeline/">AWS Data Pipelines</a> for orchestration of our ETL and ML jobs in Recommenders, and they have a number of shortcomings: they are not actively maintained by AWS, do not support newer hardware, lack Terraform support, have limited error recovery options, and do not scale well for complex jobs. We’re actively looking at replacements for this technology.</p>
Pipelines: Kafka with JSON schema	HOLD	Engineering	false	<p>Although JSON schemas offer stronger validation rules than Avro, the Confluent ecosystem does not currently support JSON schemas consistently. The support across the ecosystem is inconsistent, and some components fail to work with schemas that have been generated by other components. We are now defaulting to using Avro for Kafka within Confluent, though we may revisit the decision if Confluent matures.</p>
Pact tests for API contracts	HOLD	Quality	false	<p>Our legacy APIs currently use <a href="https://docs.pact.io/">Pact</a> tests to perform contract testing before deployment. There are a number of problems with this approach: contracts do not reflect actual usage, contracts are difficult to refactor, error reporting is unhelpful. We would do a better job by migrating these tests to a service test layer and writing them in code rather than JSON. In general, the approach of getting clients to define the tests has not worked well for us.</p>
Granular libraries	HOLD	Techniques	false	
