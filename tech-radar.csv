name,ring,quadrant,isNew,description
"Data quality monitoring in New Relic","ADOPT","Quality","false","<p>We already use <a href=""https://newrelic.com/"">New Relic</a> to dashboard and alert system health, and it’s the natural choice for doing the same with data health. Some of our pipelines already send data metrics to New Relic in addition to storing them on S3, and we should make this the standard for pipelines going forward.</p>"
"localstack for integration testing with AWS","ADOPT","Quality","false","<p>Our historical approaches for components which interact with AWS has either been to mock the interactions or run against a real environment. The <a href=""https://github.com/localstack/localstack"">localstack</a> library enable us to write tests which are stronger than mock tests, and are not coupled to real environments.</p>"
"testcontainers with docker-compose for containerised tests","ADOPT","Quality","false","<p>We have used <a href=""https://www.testcontainers.org/"">Testcontainers</a> with docker-compose to simplify testing against containerised services and it has increased the test strength and reduced test complexity. Building on top of docker-compose also ensures that our test environment aligns with our command line environment.</p>"
"Documenting and prototyping ETL work","ADOPT","Techniques","false","<p>Historically large ETL jobs been slow to deliver because issues are often only found late in implementation where they are costly to correct. Recently we’ve accelerated delivery by using a slightly different process. We document the logical flow of the ETL on the wiki, a developer then implements a disposable prototype in Databricks, and then another developer implements the production job. This ensures that any issues are identified before delivery starts when they are cheap to resolve, and has the additional benefit that we have good documentation of the job for the future. We should continue using this pattern on new jobs.</p>"
"Incremental delivery","ADOPT","Techniques","false","<p>We tend to deliver new functionality to our customers in one large deliverable. Recently we’ve been thinking harder about how we can slice stories more thinly and deliver incrementally, and it’s helping us to reduce risk, provide value earlier, and deliver more reliably. We should keep pushing in this direction.</p>"
"Pipelines: Delta Lake","TRIAL","Engineering","false","<p><a href=""https://delta.io/"">Delta Lake</a> is a new storage layer that adds ACID transactions and versioning to data sets. We have basic implementations of these features in our Data Access Layer (DAL) but Delta Lake offers support for concurrent read/write which we currently lack, and may reduce our data set sizes by storing deltas. We will trial using it as a format on some of our new data sets.</p>"
"SonarQube as a useful quality metric","TRIAL","Quality","false","<p><a href=""https://www.sonarqube.org/"">SonarQube</a> is used as standard in our builds, but the results are mostly ignored because the configured profiles give very poor signal-to-noise. If we are being pushed to use this more in the future and results will be monitored by management then we should experiment with tweaking the configuration to see if we can make it useful for us.</p>"
"Feature Store","TRIAL","Techniques","false","<p>Data Science experiments are currently slowed down by needing to ETL data sets into a useful form for models to consume. When successful, experiments are slow to deliver to production because the ETL pipeline needs to be built by engineering. We should trial building a <a href=""https://www.featurestore.org/"">Feature Store</a> so that Data Scientists work on features rather than raw data.</p>"
"ML: Polynote","ASSESS","Engineering","false","<p>Investigate <a href=""https://polynote.org/"">Polynote</a> for cheap experiments and automation.</p>"
"ML: flyte","ASSESS","Engineering","false","<p>Investigate <a href=""https://github.com/flyteorg/flyte"">flyteorg/flyte</a> for MLOps</p>"
"Orchestration: Airflow","ASSESS","Engineering","false","<p>We’re currently looking to replace our orchestration framework. <a href=""https://airflow.apache.org/"">Apache Airflow</a> is a mature and stable offering in this space that we should investigate.</p> <p>(See also <a href=""https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b"">Picking A Kubernetes Orchestrator: Airflow, Argo, and Prefect</a>)</p>"
"Orchestration: Argo","ASSESS","Engineering","false","<p>Investigate <a href=""https://argoproj.github.io/argo-cd/"">Argo CD</a> for orchestration</p> <p>(See also <a href=""https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b"">Picking A Kubernetes Orchestrator: Airflow, Argo, and Prefect</a>)</p>"
"Orchestration: Metaflow","ASSESS","Engineering","false","<p>Investigate <a href=""https://metaflow.org/"">Metaflow</a> for general orchestration</p>"
"Orchestration: Prefect","ASSESS","Engineering","false","<p>Investigate <a href=""https://docs.prefect.io/orchestration/"">Prefect</a> for orchestration</p> <p>(See also <a href=""https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b"">Picking A Kubernetes Orchestrator: Airflow, Argo, and Prefect</a>)</p>"
"Pipelines: AWS Glue","ASSESS","Engineering","false","<p>We have been looking at ways to reduce the time it takes to write our ETL jobs. <a href=""https://aws.amazon.com/glue/"">AWS Glue</a> is a managed ETL service which provides drag-and-drop ETL logic, integration with S3 batch and Kafka streaming sources, and a data catalogue which abstracts out the location and format of the data to make it simple to combine data from different sources. There are many in-built transformations for ETL, and custom transformations can be loaded.</p> <p>The features it provides look like they might satisfy some of the needs we have (reducing the time to write ETL jobs, combining data from multiple sources, discovering data sets). We should assess whether this is useful either as a part of our experimentation platform or our production systems.</p>"
"Pipelines: Kedro","ASSESS","Engineering","false","<p>Data Science are starting to use <a href=""https://kedro.readthedocs.io/en/stable/"">Kedro</a> for reproducible pipelines. These are currently run from developer machines, using Databricks to allocate compute resources from AWS.</p> <p>We want to reduce time taken for bringing their experiments and pipelines to production, so it is worth looking at what might be required to run Kedro pipelines in production. There are integrations with Airflow and AWS Batch which might align easily with our current infrastructure.</p>"
"Pipelines: Spark over Kafka","ASSESS","Engineering","false","<p>We currently use Spark for our batch big data jobs, but are looking at how to move to an incremental and streaming model -- this will simplify integration with the data platform, reduce latency, and reduce costs. Kafka streaming may be the choice for Kafka-to-Kafka jobs, but we should also investigate whether Spark streaming over Kafka will allow more reuse of components and perhaps support both batch and streaming jobs.</p>"
"Pipelines: Spark over Kubernetes","ASSESS","Engineering","false","<p>We currently run our Spark jobs using AWS EMR. This generally works fine, but there are some shortcomings: clusters are not very resilient, logs are difficult to access and verbose, clusters are often oversized, and we have limited control over the stack used. Spark has added the ability to run over Kubernetes and AWS offers <a href=""https://aws.amazon.com/blogs/opensource/deploying-spark-jobs-on-amazon-eks/"">some support</a> in this area and this may remove some of the shortcomings we see with EMR.</p>"
"AWS Cloud Development Kit as a Terraform replacement","ASSESS","Infrastructure","false","<p>We’ve found that building complex infrastructure in Terraform is difficult due to the weak support for conditionals and parameterisation. <a href=""https://aws.amazon.com/cdk/"">AWS Cloud Development Kit</a> is a fully featured software framework to build infrastructure programatically and might be a better solution for more complex infrastructure.</p>"
"Backstage as a service portal","ASSESS","Infrastructure","false","<p>We have many APIs and services, and no centralised hub with documentation to direct developers to our services. <a href=""https://backstage.io/"">Backstage</a> is Spotify’s solution for providing this service. We should assess whether it’s useful for our needs.</p>"
"CI/CD: Tekton over Kubernetes","ASSESS","Infrastructure","false","<p><a href=""https://tekton.dev/"">Tekton</a> is a Kubernetes based CI/CD pipeline. We have found that building complex CI/CD workflows in Jenkins is costly, error prone, and hard to test. We already use Kubernetes to scale our services, so Tekton might fit well with our current architecture. We should assess whether it’s better than Jenkins for our CI/CD workflows.</p>"
"Orchestration: Spinnaker","ASSESS","Infrastructure","false","<p>Investigate <a href=""https://spinnaker.io/concepts/#application-deployment"">Spinnaker</a> for deployment orchestration</p>"
"APIs: Akka","HOLD","Engineering","false","<p>We’ve used <a href=""https://akka.io/"">Akka</a> in a few different forms on several projects, including AkkaHTTP for APIs and Akka Flow for long running batch processing jobs. In the majority of those cases, the technology added incidental complexity and difficulty rather than simplifying the work. We found it difficult to debug problems in the asynchronous flows, profiling was hard, and the application was difficult to tune. It may be that there are problems where Akka is a good fit, but for APIs and batch processing jobs there are simpler alternatives which we’d pick in preference next time.</p>"
"ML: Kubeflow","HOLD","Engineering","false","<p>We already use Kubernetes to scale our services, and running ML models on Kubernetes using <a href=""https://www.kubeflow.org/docs/about/kubeflow/"">Kubeflow</a> would fit well with our existing architecture.</p> <p>The roadmap for Kubeflow looks ambitious, but it is evolving unevenly. Much of the documentation seems incomplete or out of date and some parts of the ecosystem seem to be discontinued (e.g., Fairing is a version behind and hasn’t been updated since July 2020) or just very light on details. There are also several stories from the community about difficulties with the platform (e.g., <a href=""https://www.datarevenue.com/en-blog/kubeflow-not-ready-for-production"">Kubeflow: Not ready for production?</a>).</p>"
"Orchestration: AWS Data Pipelines","HOLD","Engineering","false","<p>We use <a href=""https://aws.amazon.com/datapipeline/"">AWS Data Pipelines</a> for orchestration of our ETL and ML jobs in Recommenders, and they have a number of shortcomings: they are not actively maintained by AWS, do not support newer hardware, lack Terraform support, have limited error recovery options, and do not scale well for complex jobs. We’re actively looking at replacements for this technology.</p>"
"Pipelines: Kafka with JSON schema","HOLD","Engineering","false","<p>Although JSON schemas offer stronger validation rules than Avro, the Confluent ecosystem does not currently support JSON schemas consistently. The support across the ecosystem is inconsistent, and some components fail to work with schemas that have been generated by other components. We are now defaulting to using Avro for Kafka within Confluent, though we may revisit the decision if Confluent matures.</p>"
"Great Expectations for data checks","HOLD","Quality","false","<p>We need stronger data checks to ensure that we are alerted when our data deviates from what we expect. <a href=""https://greatexpectations.io/"">Great Expectations</a> is a Python library aimed at these types of data checks.</p> <p>It looks like a reasonable framework, but doesn’t fit well with our existing stack and the benefits it offers can easily be implemented in our DAL. We should look at it for ideas, but it’s not worth us switching to it.</p>"
"Pact tests for API contracts","HOLD","Quality","false","<p>Our legacy APIs currently use <a href=""https://docs.pact.io/"">Pact</a> tests to perform contract testing before deployment. There are a number of problems with this approach: contracts do not reflect actual usage, contracts are difficult to refactor, error reporting is unhelpful. We would do a better job by migrating these tests to a service test layer and writing them in code rather than JSON. In general, the approach of getting clients to define the tests has not worked well for us.</p>"
"Granular libraries","HOLD","Techniques","false","<p>We are struggling to refactor and renovate our code because the library abstractions we have built are too granular. We should consider reducing the number of abstraction layers in our systems, and focus more on code agility than in reducing duplication to the absolute minimum.</p>"
