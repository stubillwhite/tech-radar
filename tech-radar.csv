name,ring,quadrant,isNew,description
"Data Quality: Quality monitoring in New Relic","ADOPT","Languages & Frameworks","false","<p>We already use <a href=""https://newrelic.com/"">New Relic</a> to dashboard and alert system health, and it’s the natural choice for doing the same with data health. Some of our pipelines already send data metrics to New Relic in addition to storing them on S3, and we should make this the standard for pipelines going forward.</p>"
"localstack for integration testing with AWS","ADOPT","Languages & Frameworks","false","<p>Our historical approaches for components which interact with AWS has either been to mock the interactions or run against a real environment. The <a href=""https://github.com/localstack/localstack"">localstack</a> library enable us to write tests which are stronger than mock tests, and are not coupled to real environments.</p>"
"testcontainers with docker-compose for containerised tests","ADOPT","Languages & Frameworks","false","<p>We have used <a href=""https://www.testcontainers.org/"">Testcontainers</a> with docker-compose to simplify testing against containerised services and it has increased the test strength and reduced test complexity. Building on top of docker-compose also ensures that our test environment aligns with our command line environment.</p>"
"ETL: Prototyping ETL work","ADOPT","Techniques","false","<p>Historically large ETL jobs been slow to deliver because issues are often only found late in implementation where they are costly to correct. Recently we’ve accelerated delivery by using a slightly different process. We document the logical flow of the ETL on the wiki, a developer then implements a disposable prototype in Databricks, and then another developer implements the production job. This ensures that any issues are identified before delivery starts when they are cheap to resolve, and has the additional benefit that we have good documentation of the job for the future. We should continue using this pattern on new jobs.</p>"
"Feature Store","ADOPT","Techniques","false","<p>We built a <a href=""https://www.featurestore.org/"">Feature Store</a> for one of our recent products to host features for models to consume. This will reduce test/train skew and has accelerated Data Science delivery of new models into production. We should adopt this practice for future models we deliver, and start to build a library of useful features for Data Scientists to use.</p>"
"Incremental delivery","ADOPT","Techniques","false","<p>We tend to deliver new functionality to our customers in one large deliverable. Recently we’ve been thinking harder about how we can slice stories more thinly and deliver incrementally, and it’s helping us to reduce risk, provide value earlier, and deliver more reliably. We should keep pushing in this direction.</p>"
"Orchestration: Airflow","ADOPT","Tools","false","<p>We’re migrating our orchestration framework from AWS Data Pipelines to <a href=""https://airflow.apache.org/"">Apache Airflow</a>. This has moved from TRIAL to ADOPT because initial Airflow spikes were promising, and now that AWS Data Pipelines are end-of-life we have no option but to make the change.</p>"
"Data Quality: Great Expectations for data checks","TRIAL","Languages & Frameworks","false","<p>We need stronger data checks to ensure that we are alerted when our data deviates from what we expect. <a href=""https://greatexpectations.io/"">Great Expectations</a> is a Python library aimed at these types of data checks.</p> <p>This has evolved since we last looked at it and is increasingly gaining momentum. We should assess whether it is useful by running a cheap proof-of-concept trial.</p>"
"Data Quality: OpenLineage for data lineage tracking","TRIAL","Languages & Frameworks","false","<p>OpenLineage is an open standard for tracking data lineage in which tools send information to a central server when they use or generate data, and this usage information can track the lineage of a data set back and forward in time.</p> <p>As we focus more on data quality lineage tracking will become increasingly important, and OpenLineage could fill that gap. There are several interesting integrations and synergies with our tools (<a href=""https://openlineage.io/docs/integrations/spark/"">Spark</a>, <a href=""https://openlineage.io/docs/integrations/airflow/"">Airflow</a>, <a href=""https://openlineage.io/docs/integrations/great-expectations"">Great Expectations</a>, and <a href=""https://marquezproject.github.io/marquez/"">Marquez</a> for visualisation).</p> <p>We should consider a small proof-of-concept to trial the tools and assess usefulness.</p>"
"SonarQube as a useful quality metric","TRIAL","Languages & Frameworks","false","<p><a href=""https://www.sonarqube.org/"">SonarQube</a> is used as standard in our builds, but the results are mostly ignored because the configured profiles give very poor signal-to-noise. If we are being pushed to use this more in the future and results will be monitored by management then we should experiment with tweaking the configuration to see if we can make it useful for us.</p>"
"Tracking tech health rather than tech debt","TRIAL","Techniques","false","<p>Technical debt is a recurring topic for product owners and engineering but the term isn’t particularly helpful. There’s no differentiation between ""good"" and ""bad"" technical debt, and it doesn’t help focus attention on the areas where paying off debt is useful.</p> <p>Some teams are experimenting with flipping the conversation. Instead of talking about areas with debt (which legacy systems may have a lot of), they talk about the areas that are good. By ensuring that areas that need rapid iteration are healthy, we can focus attention where it will have the best payoff. <a href=""https://www.rea-group.com/about-us/news-and-insights/blog/what-good-software-looks-like-at-rea/"">REA</a> have a good example of what ""good"" looks like for their teams.</p> <p>I’d like to experiment with this for teams here to see if it helps focus conversation.</p>"
"Pipelines: Delta Lake","TRIAL","Tools","false","<p><a href=""https://delta.io/"">Delta Lake</a> is a new storage layer that adds ACID transactions and versioning to data sets. We have basic implementations of these features in our Data Access Layer (DAL) but Delta Lake offers support for concurrent read/write which we currently lack, and may reduce our data set sizes by storing deltas. We will trial using it as a format on some of our new data sets.</p> <p>This is also <a href=""https://delta.io/blog/2023-04-06-deltalake-aws-lambda-wrangler-pandas/"">supported in AWS Lambda</a>, so hybrid streaming/batch workflows on the same data set are now possible.</p>"
"Pipelines: Kedro","TRIAL","Tools","false","<p>Data Science are starting to use <a href=""https://kedro.readthedocs.io/en/stable/"">Kedro</a> for reproducible pipelines. These are currently run from developer machines, using Databricks to allocate compute resources from AWS.</p> <p>We want to reduce time taken for bringing their experiments and pipelines to production, so it is worth looking at what might be required to run Kedro pipelines in production. There are integrations with Airflow and AWS Batch which might align easily with our current infrastructure.</p>"
"Data Quality: pandera for data checks","ASSESS","Languages & Frameworks","false","<p><a href=""https://pandera.readthedocs.io/en/stable/"">pandera</a> is an alternative to Great Expectations. It is Spark compatible, and because it is Python-based and lightweight it may be more suitable for data science to write quick tests.</p>"
"Data Quality: popmon for data checks","ASSESS","Languages & Frameworks","false","<p><a href=""https://github.com/ing-bank/popmon"">popmon︎</a> is a popular Python library for monitoring population shifts in data sets. This could be useful for monitoring our model inputs to verify that our assumptions continue to hold in production.</p>"
"Backstage as a service portal","ASSESS","Platforms","false","<p>We have many APIs and services, and no centralised hub with documentation to direct developers to our services. <a href=""https://backstage.io/"">Backstage</a> is Spotify’s solution for providing this service, and we now have an instance of this running in the group. We should assess whether it’s useful for our needs, and if so then start hosting our content there.</p>"
"LLMs and GPT based applications","ASSESS","Platforms","false","<p>ChatGPT and LLMs are rapidly evolving new capabilities and opening up new applications. We should ensure we are not left behind and should start experimenting with the technology to better understand the capabilities and limitations.</p>"
"Orchestration: Spinnaker","ASSESS","Platforms","false","<p>Investigate <a href=""https://spinnaker.io/concepts/#application-deployment"">Spinnaker</a> for deployment orchestration</p>"
"CI/CD: Tekton over Kubernetes","ASSESS","Tools","false","<p><a href=""https://tekton.dev/"">Tekton</a> is a Kubernetes based CI/CD pipeline. We have found that building complex CI/CD workflows in Jenkins is costly, error prone, and hard to test. We already use Kubernetes to scale our services, so Tekton might fit well with our current architecture. We should assess whether it’s better than Jenkins for our CI/CD workflows.</p>"
"ETL: AWS Glue","ASSESS","Tools","false","<p>We have been looking at ways to reduce the time it takes to write our ETL jobs. <a href=""https://aws.amazon.com/glue/"">AWS Glue</a> is a managed ETL service which provides drag-and-drop ETL logic, integration with S3 batch and Kafka streaming sources, and a data catalogue which abstracts out the location and format of the data to make it simple to combine data from different sources. There are many in-built transformations for ETL, and custom transformations can be loaded.</p> <p>The features it provides look like they might satisfy some of the needs we have (reducing the time to write ETL jobs, combining data from multiple sources, discovering data sets). We should assess whether this is useful either as a part of our experimentation platform or our production systems.</p>"
"ETL: Spark over Kafka","ASSESS","Tools","false","<p>We currently use Spark for our batch big data jobs, but are looking at how to move to an incremental and streaming model -- this will simplify integration with the data platform, reduce latency, and reduce costs. Kafka streaming may be the choice for Kafka-to-Kafka jobs, but we should also investigate whether Spark streaming over Kafka will allow more reuse of components and perhaps support both batch and streaming jobs.</p>"
"ETL: Spark over Kubernetes","ASSESS","Tools","false","<p>We currently run our Spark jobs using AWS EMR. This generally works fine, but there are some shortcomings: clusters are not very resilient, logs are difficult to access and verbose, clusters are often oversized, and we have limited control over the stack used.</p> <p>EMR on EKS is looking increasingly attractive -- it is <a href=""https://aws.amazon.com/blogs/big-data/amazon-emr-on-eks-widens-the-performance-gap-run-apache-spark-workloads-5-37-times-faster-and-at-4-3-times-lower-cost/"">faster and cheaper than EMR</a>, and <a href=""https://aws.amazon.com/about-aws/whats-new/2023/04/emr-eks-apache-spark-java-11/"">now supports Java 11</a> more easily. We should assess the costs of trialling this.</p>"
"ML: Polynote","ASSESS","Tools","false","<p>Investigate <a href=""https://polynote.org/"">Polynote</a> for cheap experiments and automation.</p>"
"ML: flyte","ASSESS","Tools","false","<p>Investigate <a href=""https://github.com/flyteorg/flyte"">flyteorg/flyte</a> for MLOps</p>"
"Pact tests for API contracts","HOLD","Languages & Frameworks","false","<p>Our legacy APIs currently use <a href=""https://docs.pact.io/"">Pact</a> tests to perform contract testing before deployment. There are a number of problems with this approach: contracts do not reflect actual usage, contracts are difficult to refactor, error reporting is unhelpful. We would do a better job by migrating these tests to a service test layer and writing them in code rather than JSON. In general, the approach of getting clients to define the tests has not worked well for us.</p>"
"Granular libraries","HOLD","Techniques","false","<p>We are struggling to refactor and renovate our code because the library abstractions we have built are too granular. We should consider reducing the number of abstraction layers in our systems, and optimise for agility rather than for minimising reducing duplication.</p>"
"APIs: Akka","HOLD","Tools","false","<p><a href=""https://akka.io/"">Akka</a> and frameworks built on top of it (like AkkaHTTP for APIs, and Akka Flow for long-running jobs) has moved to HOLD and we aren’t considering it for new projects.</p> <p>In the majority of cases when we used it, the technology added incidental complexity and difficulty rather than simplifying the work. We found it difficult to debug problems in the asynchronous flows, profiling was hard, and the application was difficult to tune. It may be that there are problems where Akka is a good fit, but for APIs and batch processing jobs there are simpler alternatives. Additionally, the <a href=""https://www.lightbend.com/blog/why-we-are-changing-the-license-for-akka"">license</a> has recently become more restrictive and this affects projects built on top of Akka.</p>"
"ML: Kubeflow","HOLD","Tools","false","<p>We already use Kubernetes to scale our services, and running ML models on Kubernetes using <a href=""https://www.kubeflow.org/docs/about/kubeflow/"">Kubeflow</a> would fit well with our existing architecture.</p> <p>The roadmap for Kubeflow looks ambitious, but it is evolving unevenly. Much of the documentation seems incomplete or out of date and some parts of the ecosystem seem to be discontinued (e.g., Fairing is a version behind and hasn’t been updated since July 2020) or just very light on details. There are also several stories from the community about difficulties with the platform (e.g., <a href=""https://www.datarevenue.com/en-blog/kubeflow-not-ready-for-production"">Kubeflow: Not ready for production?</a>).</p>"
"Orchestration: AWS Data Pipelines","HOLD","Tools","false","<p>We use <a href=""https://aws.amazon.com/datapipeline/"">AWS Data Pipelines</a> for orchestration of our ETL and ML jobs in Recommenders, and they have a number of shortcomings: they are not actively maintained by AWS, do not support newer hardware, lack Terraform support, have limited error recovery options, and do not scale well for complex jobs. We’re actively looking at replacements for this technology.</p>"
"Orchestration: Argo","HOLD","Tools","false","<p>We had intended to investigate <a href=""https://argoproj.github.io/argo-cd/"">Argo CD</a> for orchestration, but this is now on hold as we are preferring Airflow because it is used by other teams in the group.</p> <p>(See also <a href=""https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b"">Picking A Kubernetes Orchestrator: Airflow, Argo, and Prefect</a>)</p>"
"Orchestration: Metaflow","HOLD","Tools","false","<p>We had intended to investigate <a href=""https://metaflow.org/"">Metaflow</a> for general orchestration, but this is now on hold as we are preferring Airflow because it is used by other teams in the group.</p>"
"Orchestration: Prefect","HOLD","Tools","false","<p>We had intended to investigate <a href=""https://docs.prefect.io/orchestration/"">Prefect</a> for orchestration, but this is now on hold as we are preferring Airflow because it is used by other teams in the group.</p> <p>(See also <a href=""https://medium.com/arthur-engineering/picking-a-kubernetes-orchestrator-airflow-argo-and-prefect-83539ecc69b"">Picking A Kubernetes Orchestrator: Airflow, Argo, and Prefect</a>)</p>"
"Pipelines: Kafka with JSON schema","HOLD","Tools","false","<p>Although JSON schemas offer stronger validation rules than Avro, the Confluent ecosystem does not currently support JSON schemas consistently. The support across the ecosystem is inconsistent, and some components fail to work with schemas that have been generated by other components. We are now defaulting to using Avro for Kafka within Confluent, though we may revisit the decision if Confluent matures.</p>"
